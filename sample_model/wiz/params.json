{
    "attn": "mlp",
    "batch_size": 8,
    "beam_size": 1,
    "bidirectional": true,
    "ckpt": "best.model",
    "data_dir": "./sample_processed_data/wizard/",
    "dropout": 0.2,
    "embed_file": null,
    "embed_size": 300,
    "gpu": 3,
    "grad_clip": 5.0,
    "hidden_size": 256,
    "ignore_unk": true,
    "length_average": true,
    "log_steps": 1,
    "lr": 0.0005,
    "lr_decay": 0.5,
    "max_dec_len": 20,
    "max_dlg_hop": 3,
    "max_kb_hop": 3,
    "max_kb_len": 98,
    "max_len": 48,
    "max_vocab_size": 30000,
    "min_kb_len": 0,
    "min_len": 1,
    "num_epochs": 30,
    "num_layers": 1,
    "optimizer": "Adam",
    "output_dir": "./outputs/wiz",
    "patience": 5,
    "save_dir": "./sample_model/wiz",
    "share_vocab": false,
    "test": false,
    "tie_embedding": true,
    "use_embed": true,
    "use_gpu": true,
    "valid_steps": 500,
    "vocab_type": "dlg-shared-seen",
    "with_bridge": false
}