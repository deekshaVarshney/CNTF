{
    "attn": "mlp",
    "batch_size": 8,
    "beam_size": 4,
    "bert_config": "./source/model/wiz_config.json",
    "bidirectional": false,
    "ckpt": "best.model",
    "data_dir": "./sample_processed_data/wiz/",
    "dropout": 0.2,
    "embed_file": ".././glove.840B.300d.txt",
    "embed_size": 300,
    "fp16": false,
    "fp16_opt_level": "O1",
    "gpu": 3,
    "grad_accum_steps": 1,
    "grad_clip": 5.0,
    "hidden_size": 256,
    "ignore_unk": true,
    "length_average": true,
    "log_steps": 2,
    "lr": 0.0005,
    "lr_decay": 0.5,
    "max_dec_len": 20,
    "max_dlg_hop": 3,
    "max_kb_hop": 3,
    "max_kb_len": 98,
    "max_len": 48,
    "max_vocab_size": 30000,
    "min_kb_len": 0,
    "min_len": 1,
    "n_gpu": 1,
    "num_attn_layers": 2,
    "num_epochs": 30,
    "num_heads": 8,
    "num_rnn_layers": 1,
    "optimizer": "Adam",
    "output_dir": "./outputs/cmu_new",
    "patience": 5,
    "pf_dim": 2048,
    "pre_epochs": 10,
    "save_dir": "./sample_model/wiz",
    "share_vocab": false,
    "test": false,
    "tie_embedding": false,
    "use_embed": true,
    "use_gpu": true,
    "valid_steps": 500,
    "vocab_type": "dlg-seen",
    "window_size": 3,
    "with_bridge": false
}